# coding: utf-8

"""
    CircleCI API

    This describes the resources that make up the CircleCI API v2.

    The version of the OpenAPI document: v2
    Generated by: https://konfigthis.com
"""

from datetime import date, datetime  # noqa: F401
import decimal  # noqa: F401
import functools  # noqa: F401
import io  # noqa: F401
import re  # noqa: F401
import typing  # noqa: F401
import typing_extensions  # noqa: F401
import uuid  # noqa: F401

import frozendict  # noqa: F401

from circle_ci_python_sdk import schemas  # noqa: F401


class InsightsGetFlakyTestsResponseFlakyTestsItem(
    schemas.DictSchema
):
    """
    This class is auto generated by Konfig (https://konfigthis.com)
    """


    class MetaOapg:
        required = {
            "job-number",
            "workflow-id",
            "file",
            "job-name",
            "test-name",
            "classname",
            "workflow-name",
            "times-flaked",
            "source",
            "pipeline-number",
            "workflow-created-at",
        }
        
        class properties:
            workflow_created_at = schemas.StrSchema
            workflow_id = schemas.AnyTypeSchema
            classname = schemas.StrSchema
            
            
            class pipeline_number(
                schemas.ComposedSchema,
            ):
            
            
                class MetaOapg:
                    all_of_0 = schemas.Int64Schema
                    
                    
                    class all_of_1(
                        schemas.Int64Schema
                    ):
                        pass
                    
                    @classmethod
                    @functools.lru_cache()
                    def all_of(cls):
                        # we need this here to make our import statements work
                        # we must store _composed_schemas in here so the code is only run
                        # when we invoke this method. If we kept this at the class
                        # level we would get an error because the class level
                        # code would be run when this module is imported, and these composed
                        # classes don't exist yet because their module has not finished
                        # loading
                        return [
                            cls.all_of_0,
                            cls.all_of_1,
                        ]
            
            
                def __new__(
                    cls,
                    *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
                    _configuration: typing.Optional[schemas.Configuration] = None,
                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
                ) -> 'pipeline_number':
                    return super().__new__(
                        cls,
                        *args,
                        _configuration=_configuration,
                        **kwargs,
                    )
            workflow_name = schemas.StrSchema
            test_name = schemas.StrSchema
            job_name = schemas.StrSchema
            
            
            class job_number(
                schemas.ComposedSchema,
            ):
            
            
                class MetaOapg:
                    all_of_0 = schemas.Int64Schema
                    
                    
                    class all_of_1(
                        schemas.Int64Schema
                    ):
                        pass
                    
                    @classmethod
                    @functools.lru_cache()
                    def all_of(cls):
                        # we need this here to make our import statements work
                        # we must store _composed_schemas in here so the code is only run
                        # when we invoke this method. If we kept this at the class
                        # level we would get an error because the class level
                        # code would be run when this module is imported, and these composed
                        # classes don't exist yet because their module has not finished
                        # loading
                        return [
                            cls.all_of_0,
                            cls.all_of_1,
                        ]
            
            
                def __new__(
                    cls,
                    *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
                    _configuration: typing.Optional[schemas.Configuration] = None,
                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
                ) -> 'job_number':
                    return super().__new__(
                        cls,
                        *args,
                        _configuration=_configuration,
                        **kwargs,
                    )
            
            
            class times_flaked(
                schemas.Int64Schema
            ):
                pass
            source = schemas.StrSchema
            file = schemas.StrSchema
            
            
            class time_wasted(
                schemas.ComposedSchema,
            ):
            
            
                class MetaOapg:
                    all_of_0 = schemas.Int64Schema
                    
                    
                    class all_of_1(
                        schemas.Int64Schema
                    ):
                        pass
                    
                    @classmethod
                    @functools.lru_cache()
                    def all_of(cls):
                        # we need this here to make our import statements work
                        # we must store _composed_schemas in here so the code is only run
                        # when we invoke this method. If we kept this at the class
                        # level we would get an error because the class level
                        # code would be run when this module is imported, and these composed
                        # classes don't exist yet because their module has not finished
                        # loading
                        return [
                            cls.all_of_0,
                            cls.all_of_1,
                        ]
            
            
                def __new__(
                    cls,
                    *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
                    _configuration: typing.Optional[schemas.Configuration] = None,
                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
                ) -> 'time_wasted':
                    return super().__new__(
                        cls,
                        *args,
                        _configuration=_configuration,
                        **kwargs,
                    )
            __annotations__ = {
                "workflow-created-at": workflow_created_at,
                "workflow-id": workflow_id,
                "classname": classname,
                "pipeline-number": pipeline_number,
                "workflow-name": workflow_name,
                "test-name": test_name,
                "job-name": job_name,
                "job-number": job_number,
                "times-flaked": times_flaked,
                "source": source,
                "file": file,
                "time-wasted": time_wasted,
            }
    
    file: MetaOapg.properties.file
    classname: MetaOapg.properties.classname
    source: MetaOapg.properties.source
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["workflow-created-at"]) -> MetaOapg.properties.workflow_created_at: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["workflow-id"]) -> MetaOapg.properties.workflow_id: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["classname"]) -> MetaOapg.properties.classname: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["pipeline-number"]) -> MetaOapg.properties.pipeline_number: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["workflow-name"]) -> MetaOapg.properties.workflow_name: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["test-name"]) -> MetaOapg.properties.test_name: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["job-name"]) -> MetaOapg.properties.job_name: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["job-number"]) -> MetaOapg.properties.job_number: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["times-flaked"]) -> MetaOapg.properties.times_flaked: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["file"]) -> MetaOapg.properties.file: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["time-wasted"]) -> MetaOapg.properties.time_wasted: ...
    
    @typing.overload
    def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
    
    def __getitem__(self, name: typing.Union[typing_extensions.Literal["workflow-created-at", "workflow-id", "classname", "pipeline-number", "workflow-name", "test-name", "job-name", "job-number", "times-flaked", "source", "file", "time-wasted", ], str]):
        # dict_instance[name] accessor
        return super().__getitem__(name)
    
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["workflow-created-at"]) -> MetaOapg.properties.workflow_created_at: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["workflow-id"]) -> MetaOapg.properties.workflow_id: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["classname"]) -> MetaOapg.properties.classname: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["pipeline-number"]) -> MetaOapg.properties.pipeline_number: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["workflow-name"]) -> MetaOapg.properties.workflow_name: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["test-name"]) -> MetaOapg.properties.test_name: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["job-name"]) -> MetaOapg.properties.job_name: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["job-number"]) -> MetaOapg.properties.job_number: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["times-flaked"]) -> MetaOapg.properties.times_flaked: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["file"]) -> MetaOapg.properties.file: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["time-wasted"]) -> typing.Union[MetaOapg.properties.time_wasted, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
    
    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["workflow-created-at", "workflow-id", "classname", "pipeline-number", "workflow-name", "test-name", "job-name", "job-number", "times-flaked", "source", "file", "time-wasted", ], str]):
        return super().get_item_oapg(name)
    

    def __new__(
        cls,
        *args: typing.Union[dict, frozendict.frozendict, ],
        file: typing.Union[MetaOapg.properties.file, str, ],
        classname: typing.Union[MetaOapg.properties.classname, str, ],
        source: typing.Union[MetaOapg.properties.source, str, ],
        _configuration: typing.Optional[schemas.Configuration] = None,
        **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
    ) -> 'InsightsGetFlakyTestsResponseFlakyTestsItem':
        return super().__new__(
            cls,
            *args,
            file=file,
            classname=classname,
            source=source,
            _configuration=_configuration,
            **kwargs,
        )
